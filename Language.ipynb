{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab049783",
   "metadata": {},
   "source": [
    "# <font color='#0f2f5c'>The Linguistic Locator: The marriage between Natural Language Processing and paleography.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16213184",
   "metadata": {},
   "source": [
    "### <font color='#0f2f5c'>Table of Contents</font>\n",
    "\n",
    "* [Data Gathering](#DataPrep)\n",
    "* [General use Methods](#GUM)\n",
    "    * [Decorators](#GUM_Decorators)\n",
    "    * [Methods](#GUM_Methods)\n",
    "    * [Thread Manager](#GUM_ThreadManager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed296c0",
   "metadata": {},
   "source": [
    "### As we go further and further back in history, it gets harder and harder to pin down when and where a certain piece of writing comes from. Generally, writing gets dated by looking at the handwriting and general context of history the text fits in. A text could also be dated by looking at the material it was written on itself. These fields of analysis are called paleography and codicology respectively.\n",
    "### This work still gets done by humans, but it might be possible to predict these attributes computationally. By pondering this, we arrive at the main question: What models of AI can accurately predict attributes of historical writings?\n",
    "\n",
    "### In order to answer this question, the following sub questions should be answered:\n",
    "1. How accurate does the model need to be?\n",
    "2. What models could possibly work for this application?\n",
    "3. What criteria do the writings need to meet?\n",
    "4. What attributes can we predict (accurately)?\n",
    "5. What model works best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To test this, some data should be gathered to train a potential model on. In order to do this, some criteria need to be set up and the scope of this project should be defined.\n",
    "### To start off, let's only train on texts from 1200 until 1950. 1200 is an arbitrary pick. Going earlier would get progressively harder and harder to find proper examples for that have been dated already. 1900 works as a proper endpoint, because going any more recent slowly moves us from historical to contemporary writings.\n",
    "\n",
    "### The first version of this project will only train on the following languages:\n",
    "1. Dutch\n",
    "2. German\n",
    "3. English\n",
    "4. French\n",
    "5. Italian\n",
    "\n",
    "### Per language, we should collect 3 books, at minimum. Some of these should be close to each other in time or place of writing, as to avoid the model just learning to detect writing styles of specific authors.\n",
    "\n",
    "### Now, as for the texts themselves: what rules should they meet?\n",
    "1. The time and location of writing should be known or easily extrapolated.\n",
    "2. The text shouldn't be modernized.\n",
    "3. Most of the paragraphs of the book should be at least 500 characters.\n",
    "\n",
    "### Because we are going to split the texts to train on their paragraphs, the third rule is to filter out short results. As per reference, the following excerpt from Locke's 'An Essay Concerning Humane Understanding Vol II' is 521 characters long.\n",
    "    \"As the ideas men's words stand for are of different sorts, so the way of\n",
    "    making known the ideas they stand for, when there is occasion, is also\n",
    "    different. For though DEFINING be thought the proper way to make known\n",
    "    the proper signification of words; yet there are some words that will\n",
    "    not be defined, as there are others whose precise meaning cannot be made\n",
    "    known but by definition: and perhaps a third, which partake somewhat of\n",
    "    both the other, as we shall see in the names of simple ideas, modes, and\n",
    "    substances.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}