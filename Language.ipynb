{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab049783",
   "metadata": {},
   "source": [
    "# <font color='#0f2f5c'>The Linguistic Locator: The marriage between Natural Language Processing and paleography.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16213184",
   "metadata": {},
   "source": [
    "### <font color='#0f2f5c'>Table of Contents</font>\n",
    "\n",
    "* [Research](#Research)\n",
    "    * [Stengths and Weaknesses](#Research_SaW)\n",
    "* [Data Gathering](#DataGathering)\n",
    "* [General Use Methods](#GUM)\n",
    "* [Data Preprocessing](#DataPrep)\n",
    "* [Model Testing](#Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed296c0",
   "metadata": {},
   "source": [
    "### As we go further and further back in history, it gets harder and harder to pin down when and where a certain piece of writing comes from. Generally, writing gets dated by looking at the handwriting and general context of history the text fits in. A text could also be dated by looking at the material it was written on itself. These fields of analysis are called paleography and codicology respectively.\n",
    "### This work still gets done by humans, but it might be possible to predict these attributes computationally. By pondering this, we arrive at the main question: What models of AI can accurately predict attributes of historical writings?\n",
    "\n",
    "### In order to answer this question, the following sub questions should be answered:\n",
    "1. [How accurate does the model need to be?](#SubQuestion1)\n",
    "2. [What models could possibly work for this application?](#SubQuestion2)\n",
    "3. [What criteria do the writings need to meet?](#SubQuestion3)\n",
    "4. [What attributes can we predict (accurately)?](#SubQuestion4)\n",
    "5. [What model works best?](#SubQuestion5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e279c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45099ff9",
   "metadata": {},
   "source": [
    "# <font color='#0f2f5c'>Research</font><a class=\"anchor\" id=\"Research\"></a>\n",
    "## <font color='#0f2f5c'>How accurate does the model need to be?</font><a class=\"anchor\" id=\"SubQuestion1\"></a>\n",
    "\n",
    "### Before we can get to designing the project, we first need to do some research and set some targets to test our models with further into the project. First off, we need to define some targets regarding the accuracy of the model in terms of time and location.\n",
    "### Let's start with the former. From Brent Nongbri's 'The Use and Abuse of P<sup>52</sup>: Papyrological Pitfalls in the Dating of the Fourth Gospel', we can gather that \"a period of 50 years is the least acceptable spread of time\", and that we \"should probably be to avoid dating a hand more precisely than a range of at least seventy or eighty years\". As another example, according to Bruce Griffith's 'The Paleographical Dating of P-46': \"it is difficult to construct a 95% confidence interval for NT \\[New Testament] manuscripts without allowing a century for an assigned date\".\n",
    "### With this knowledge in mind, let's set the accuracy target regarding time to 40 for now. So if the model's prediction of the year of writing of a certain text is off by more than 40 years, we deem it as inaccurate. The problem with this method, however, is that we are clamping a continuous rating to a binary state. If two texts got dated 40 and 41 years off respectively, only the former would get seen as accurate whereas a third text that has been dated only 1 year off would be seen as just as accurate as the first. That doesn't make a lot of sense. We might want to change this to something like a formula to judge accuracy in the future.\n",
    "\n",
    "### But what about location? As of writing this, unfortunately I haven't been able to find any relevant information regarding pinning down the location of writing - or localizing - of a text.\n",
    "\n",
    "## <font color='#0f2f5c'>Strengths and Weaknesses</font><a class=\"anchor\" id=\"Research_SaW\"></a>\n",
    "\n",
    "## <font color='#0f2f5c'>What models could possibly work for this application?</font><a class=\"anchor\" id=\"SubQuestion2\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e56ba6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c8cb702",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <font color='#0f2f5c'>Data Gathering</font><a class=\"anchor\" id=\"DataGathering\"></a>\n",
    "## <font color='#0f2f5c'>What criteria do the writings need to meet?</font><a class=\"anchor\" id=\"SubQuestion3\"></a>\n",
    "\n",
    "### To test this, some data should be gathered to train a potential model on. In order to do this, some criteria need to be set up and the scope of this project should be defined.\n",
    "### To start off, let's only train on texts from 1200 until 1950. 1200 is an arbitrary pick. Going earlier would get progressively harder and harder to find proper examples for that have been dated already. 1900 works as a proper endpoint, because going any more recent slowly moves us from historical to contemporary writings.\n",
    "\n",
    "### The first version of this project will only train on the following languages:\n",
    "1. Dutch\n",
    "2. German\n",
    "3. English\n",
    "4. French\n",
    "5. Italian\n",
    "\n",
    "### Per language, we should collect 3 books, at minimum. The more, the merrier, of course. Some of these should be close to each other in time or place of writing, as to avoid the model just learning to detect writing styles of specific authors.\n",
    "\n",
    "### Now, as for the texts themselves: what rules should they meet?\n",
    "1. The time and location of writing should be known or easily extrapolated.\n",
    "2. The text shouldn't be modernized.\n",
    "3. Most of the paragraphs of the book should be at least 500 characters.\n",
    "\n",
    "### Because we are going to split the texts to train on their paragraphs, the third rule is to filter out short results. As per reference, the following excerpt from Locke's 'An Essay Concerning Humane Understanding Vol II' is 521 characters long.\n",
    "    \"As the ideas men's words stand for are of different sorts, so the way of\n",
    "    making known the ideas they stand for, when there is occasion, is also\n",
    "    different. For though DEFINING be thought the proper way to make known\n",
    "    the proper signification of words; yet there are some words that will\n",
    "    not be defined, as there are others whose precise meaning cannot be made\n",
    "    known but by definition: and perhaps a third, which partake somewhat of\n",
    "    both the other, as we shall see in the names of simple ideas, modes, and\n",
    "    substances.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed26a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8b8f985",
   "metadata": {},
   "source": [
    "# <font color='#0f2f5c'>General Use Methods</font><a class=\"anchor\" id=\"GUM\"></a>\n",
    "### Before we can dive into the code, we need to define some general functions and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4202b03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def CheckFile(function):  # Requires the first argument (no keyword) to be  the filepath (Path).\n",
    "\tdef wrapper(*args, **kwargs):\n",
    "\t\tfile = args[0]\n",
    "\n",
    "\t\tif file.exists():\n",
    "\t\t\tif file.is_file:\n",
    "\t\t\t\toutput = function(*args, **kwargs)\n",
    "\n",
    "\t\t\t\treturn output\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(f\"ERROR: '{file}' is not a file.\")\n",
    "\n",
    "\t\t\toutput = function(*args, **kwargs)\n",
    "\t\t\treturn output\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"ERROR: '{file}'not found.\")\n",
    "\n",
    "\treturn wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34a413",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <font color='#0f2f5c'>Data Preprocessing</font><a class=\"anchor\" id=\"DataPrep\"></a>\n",
    "### Now that we have our data, let's first split up the entire books into paragraphs for training. Most texts can easily just be split by whitelines - so just 2 newlines. Some texts, however, can be split in a way to produce better samples using a custom separator. For this instance then, a defaultdict works perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626d104d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "SEPARATORS = defaultdict(lambda: r\"\\n\\n\")\n",
    "SEPARATORS['An Essay Concerning Humane Understanding Vol II - Locke.txt'] = r\"\\n\\n[0-9]\\.\"  # Some sources have better results with custom separators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1328088",
   "metadata": {},
   "source": [
    "### Now that we have our data, let's first split up the entire books into paragraphs for training. Most texts can easily just be split by whitelines - so just 2 newlines. Some texts, however, can be split in a way to produce better samples using a custom separator. For this instance then, a defaultdict works perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae46ad6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0  An Essay Concerning Humane Understanding Vol I...   \n",
      "1  An Essay Concerning Humane Understanding Vol I...   \n",
      "2  An Essay Concerning Humane Understanding Vol I...   \n",
      "3  An Essay Concerning Humane Understanding Vol I...   \n",
      "4  An Essay Concerning Humane Understanding Vol I...   \n",
      "\n",
      "                                                Text Language  Year  \\\n",
      "0  to conclude this is that which in short i woul...  English  1690   \n",
      "1  as the ideas men's words stand for are of diff...  English  1690   \n",
      "2  in all things therefore where we have clear ev...  English  1690   \n",
      "3  the names of mixed modes being general they st...  English  1690   \n",
      "4  first essence may be taken for the very being ...  English  1690   \n",
      "\n",
      "   Longitude Latitude  \n",
      "0     51.756    0.212  \n",
      "1     51.756    0.212  \n",
      "2     51.756    0.212  \n",
      "3     51.756    0.212  \n",
      "4     51.756    0.212  \n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Only keeping letters, numbers and spaces. Also removing empty spaces before the first letter. Based on this filter:\n",
    "# https://stackoverflow.com/questions/24676691/whats-a-good-regex-to-include-accented-characters-in-a-simple-way\n",
    "CHARACTERFILTER = r\"^( +)|[^-'\\\"a-zA-ZÀ-ÖØ-öø-ÿ0-9 ]\"  # Could've perhaps used string.punctuation for this... Oh well.\n",
    "\n",
    "splitText = dict()  # Title: [paragraph, paragraph, ...]\n",
    "\n",
    "\n",
    "@CheckFile\n",
    "def SplitText(file: Path) -> list:\n",
    "\t\"\"\"Splits the input text and returns a list of its paragraphs with all punctuation removed.\"\"\"\n",
    "\n",
    "\tglobal SEPARATORS, CHARACTERFILTER\n",
    "\n",
    "\twith open(file.resolve(), 'r', encoding='utf-8') as textFile:  # UTF-8 saves the day, regarding 'nonconventional' characters from different languages.\n",
    "\t\ttext = textFile.read().lower()\n",
    "\n",
    "\t\tsegments = re.split(SEPARATORS[textFile.name], text)\n",
    "\t\tsegments = [s.replace('\\n', ' ') for s in segments]\n",
    "\t\tsegments = [re.sub(CHARACTERFILTER, '', s) for s in segments]\n",
    "\treturn segments\n",
    "\n",
    "\n",
    "def LinkData(textData: dict, metaData: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\"\"\"Merges the newly split paragraph data and metadata regarding the texts in order to output a dataframe of paragraphs, each labeled with its metadata.\"\"\"\n",
    "\n",
    "\tlinkedData = pd.DataFrame(columns=['Title', 'Text', 'Language', 'Year', 'Longitude', 'Latitude'])\n",
    "\tfor title, textList in textData.items():\n",
    "\t\ttitle, language, year, longitude, latitude = metaData.loc[metaData['Title'] == title].squeeze().tolist()  # Not using the title.\n",
    "\n",
    "\t\tfor paragraph in textList:\n",
    "\t\t\tlinkedData.loc[len(linkedData.index)] = [title, paragraph, language, year, longitude, latitude]\n",
    "\treturn linkedData\n",
    "\n",
    "\n",
    "def GetData(textFiles: list, csv: pd.DataFrame):\n",
    "\t\"\"\"Retrieves the text data and it's metadata in order to return a merged cleaned dataset of paragraphs and addditional information.\"\"\"\n",
    "\n",
    "\tglobal splitText\n",
    "\n",
    "\tfor file in textFiles:\n",
    "\t\tdata = SplitText(file)\n",
    "\t\tdata.sort(key=len)\n",
    "\n",
    "\t\tdata = list(filter(lambda x: len(x.strip()) > 500, data))  # Elaborate on size <--> amount balance.\n",
    "\n",
    "\t\tsplitText[file.name] = data\n",
    "\tdata = LinkData(splitText, csv)\n",
    "\n",
    "\treturn data\n",
    "\n",
    "files = [Path(f'D:\\\\Documents\\\\Fontys\\\\S4\\\\Language\\\\Data\\\\Raw\\\\{file}') for file in listdir('D:\\\\Documents\\\\Fontys\\\\S4\\\\Language\\\\Data\\\\Raw')]\n",
    "\n",
    "data = GetData(files, pd.read_csv('D:\\\\Documents\\\\Fontys\\\\S4\\\\Language\\\\Data\\\\Done\\\\Metadata.csv', encoding='unicode_escape'))\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}